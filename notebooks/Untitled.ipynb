{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f32ef24-d92c-4709-ad45-b14d6d3f71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY carregada\n",
      "Sessão Spark iniciada com sucesso.\n",
      "Coletando dados da API: https://api.portaldatransparencia.gov.br/api-de-dados/bolsa-familia-por-municipio?mesAno=201907&codigoIbge=3150109&pagina=1\n",
      "Dados coletados com sucesso!\n",
      "Schema do DataFrame bruto:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- dataDisponibilizacao: string (nullable = true)\n",
      " |-- municipio: struct (nullable = true)\n",
      " |    |-- codigoIBGE: string (nullable = true)\n",
      " |    |-- nomeIBGE: string (nullable = true)\n",
      " |    |-- pais: string (nullable = true)\n",
      " |    |-- uf: struct (nullable = true)\n",
      " |    |    |-- sigla: string (nullable = true)\n",
      " |    |    |-- nome: string (nullable = true)\n",
      " |-- tipo: struct (nullable = true)\n",
      " |    |-- id: integer (nullable = true)\n",
      " |    |-- descricao: string (nullable = true)\n",
      " |    |-- descricaoDetalhada: string (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- quantidadeBeneficiados: integer (nullable = true)\n",
      "\n",
      "+--------+--------------------+-------------------------------------------+---------------------------------+-------+----------------------+\n",
      "|id      |dataDisponibilizacao|municipio                                  |tipo                             |valor  |quantidadeBeneficiados|\n",
      "+--------+--------------------+-------------------------------------------+---------------------------------+-------+----------------------+\n",
      "|33407623|NULL                |{3150109, PIAU, BRASIL, {MG, MINAS GERAIS}}|{1, Bolsa Família, Bolsa Família}|26502.0|142                   |\n",
      "+--------+--------------------+-------------------------------------------+---------------------------------+-------+----------------------+\n",
      "\n",
      "Schema do DataFrame tratado:\n",
      "root\n",
      " |-- id_pagamento: integer (nullable = true)\n",
      " |-- data_disponibilizacao: date (nullable = true)\n",
      " |-- codigo_ibge: string (nullable = true)\n",
      " |-- nome_municipio: string (nullable = true)\n",
      " |-- uf: string (nullable = true)\n",
      " |-- tipo_beneficio: string (nullable = true)\n",
      " |-- valor_total_pago: double (nullable = true)\n",
      " |-- qtd_beneficiados: integer (nullable = true)\n",
      " |-- ano_mes_referencia: string (nullable = false)\n",
      "\n",
      "Amostra dos dados tratados:\n",
      "+------------+---------------------+-----------+--------------+---+--------------+----------------+----------------+------------------+\n",
      "|id_pagamento|data_disponibilizacao|codigo_ibge|nome_municipio|uf |tipo_beneficio|valor_total_pago|qtd_beneficiados|ano_mes_referencia|\n",
      "+------------+---------------------+-----------+--------------+---+--------------+----------------+----------------+------------------+\n",
      "|33407623    |NULL                 |3150109    |PIAU          |MG |Bolsa Família |26502.0         |142             |201907            |\n",
      "+------------+---------------------+-----------+--------------+---+--------------+----------------+----------------+------------------+\n",
      "\n",
      "Salvando dados tratados no HDFS em: ./dados/gov/bolsa_familia/codigo_ibge=3150109/ano_mes=201907\n",
      "Dados salvos com sucesso no HDFS!\n",
      "Sessão Spark finalizada.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(\"API KEY carregada\")\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# --- 1. Inicialização do Spark ---\n",
    "# Cria uma sessão Spark, que é o ponto de entrada para qualquer funcionalidade do Spark.\n",
    "# O appName ajuda a identificar sua aplicação na UI do Spark.\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ColetaAPIGovernoAuxilioEmergencial\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Sessão Spark iniciada com sucesso.\")\n",
    "\n",
    "# --- 2. Extração (Extract) ---\n",
    "\n",
    "# Parâmetros para a API do Portal da Transparência\n",
    "ano_mes = \"201907\" # Data dos dados que serão coletados padrão ANO/MÊS \n",
    "codigo_ibge = \"3150109\" # Código IBGE insira aqui o código do município desejado\n",
    "pagina = 1 # Página dos dados\n",
    "\n",
    "#url da api que será consultada\n",
    "api_url = f\"https://api.portaldatransparencia.gov.br/api-de-dados/bolsa-familia-por-municipio?mesAno={ano_mes}&codigoIbge={codigo_ibge}&pagina={pagina}\"\n",
    "\n",
    "# Chave da API no header para a consulta\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"chave-api-dados\": api_key\n",
    "}\n",
    "\n",
    "print(f\"Coletando dados da API: {api_url}\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()  # Lança um erro para respostas com status 4xx/5xx\n",
    "    dados_json = response.json()\n",
    "    print(\"Dados coletados com sucesso!\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Erro ao chamar a API: {e}\")\n",
    "    spark.stop()\n",
    "\n",
    "# Se a resposta estiver vazia, não há o que processar.\n",
    "if not dados_json:\n",
    "    print(\"Nenhum dado retornado pela API. Encerrando o processo.\")\n",
    "    spark.stop()\n",
    "\n",
    "# --- 3. Transformação (Transform) ---\n",
    "# Agora, vamos converter os dados JSON em um DataFrame Spark e tratá-los.\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"dataDisponibilizacao\", StringType(), True),\n",
    "    StructField(\"municipio\", StructType([\n",
    "        StructField(\"codigoIBGE\", StringType(), True),\n",
    "        StructField(\"nomeIBGE\", StringType(), True),\n",
    "        StructField(\"pais\", StringType(), True),\n",
    "        StructField(\"uf\", StructType([\n",
    "            StructField(\"sigla\", StringType(), True),\n",
    "            StructField(\"nome\", StringType(), True)\n",
    "        ]))\n",
    "    ])),\n",
    "    StructField(\"tipo\", StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"descricao\", StringType(), True),\n",
    "        StructField(\"descricaoDetalhada\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"valor\", DoubleType(), True),\n",
    "    StructField(\"quantidadeBeneficiados\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Criamos um RDD (Resilient Distributed Dataset) a partir do JSON e depois um DataFrame.\n",
    "rdd = spark.sparkContext.parallelize(dados_json)\n",
    "df_bruto = spark.read.json(rdd, schema=schema)\n",
    "\n",
    "print(\"Schema do DataFrame bruto:\")\n",
    "df_bruto.printSchema()\n",
    "df_bruto.show(5, False)\n",
    "\n",
    "# Aplicando transformações para limpar e organizar os dados\n",
    "df_tratado = df_bruto.select(\n",
    "    col(\"id\").alias(\"id_pagamento\"),\n",
    "    to_date(col(\"dataDisponibilizacao\"), \"dd/MM/yyyy\").alias(\"data_disponibilizacao\"),\n",
    "    col(\"municipio.codigoIBGE\").alias(\"codigo_ibge\"),\n",
    "    col(\"municipio.nomeIBGE\").alias(\"nome_municipio\"),\n",
    "    col(\"municipio.uf.sigla\").alias(\"uf\"),\n",
    "    col(\"tipo.descricao\").alias(\"tipo_beneficio\"),\n",
    "    col(\"valor\").alias(\"valor_total_pago\"),\n",
    "    col(\"quantidadeBeneficiados\").alias(\"qtd_beneficiados\")\n",
    ").withColumn(\"ano_mes_referencia\", lit(ano_mes)) # Adiciona uma coluna com o período da consulta\n",
    "\n",
    "print(\"Schema do DataFrame tratado:\")\n",
    "df_tratado.printSchema()\n",
    "\n",
    "print(\"Amostra dos dados tratados:\")\n",
    "df_tratado.show(5, truncate=False)\n",
    "\n",
    "# --- 4. Carga (Load) ---\n",
    "# Salvamos o DataFrame tratado no HDFS em formato Parquet.\n",
    "# Parquet é um formato colunar otimizado para performance em análises com Spark.\n",
    "\n",
    "# O caminho no HDFS onde os dados serão salvos.\n",
    "caminho_hdfs = f\"./dados/gov/bolsa_familia/codigo_ibge={codigo_ibge}/ano_mes={ano_mes}\"\n",
    "\n",
    "print(f\"Salvando dados tratados no HDFS em: {caminho_hdfs}\")\n",
    "\n",
    "# 'overwrite' substitui os dados se o diretório já existir.\n",
    "# 'partitionBy' é útil para organizar os dados, mas como já filtramos por ano_mes,\n",
    "# incluímos ele no caminho para criar uma partição manual.\n",
    "df_tratado.write.mode(\"overwrite\").parquet(caminho_hdfs)\n",
    "\n",
    "print(\"Dados salvos com sucesso no HDFS!\")\n",
    "\n",
    "spark.stop()\n",
    "print(\"Sessão Spark finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d6e86d-f3bc-4ca9-94ba-56f6df4f0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "{\"Erro na API\":\"Chave de API não informada! Para obter a chave acesse http://www.portaldatransparencia.gov.br/api-de-dados/cadastrar-email\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"api_key\")\n",
    "\n",
    "r = requests.get(\n",
    "    \"https://api.portaldatransparencia.gov.br/api-de-dados/auxilio-emergencial-por-municipio?mesAno=202101&codigoIbge=3550308&pagina=1\",\n",
    "    headers = {\n",
    "    \"chave-api-dados\": api_key\n",
    "})\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea9a01-22fb-47aa-80dd-619a3867bdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
